{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Part-1 Data Preprocessing in python.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM/0gSg7FdCkVqNKl2Jfq8U",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KrishnaPandya-VGEC-IT/Data-Science-/blob/main/Part_1_Data_Preprocessing_in_python.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E4yeoRibK6HA"
      },
      "source": [
        "#Data Preprocessing Tools"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7AhBRRHBLFun"
      },
      "source": [
        "### Importing the libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wc99W_m2IpDF"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cBAmV8LoMA5i"
      },
      "source": [
        "### Importing the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tY4yzli5MEd2"
      },
      "source": [
        "dataset = pd.read_csv('/content/Data.csv') #reading csv file\n",
        "x = dataset.iloc[: , :-1].values #features - all rows, all cols except last one\n",
        "y = dataset.iloc[:, -1:].values #dependent variables - or [-1] in last column will also work"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j_wZfp6TPn_T",
        "outputId": "6c99493b-adbe-4899-ea10-54063fadc28e"
      },
      "source": [
        "print(x) #printing matrix of features"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['France' 44.0 72000.0]\n",
            " ['Spain' 27.0 48000.0]\n",
            " ['Germany' 30.0 54000.0]\n",
            " ['Spain' 38.0 61000.0]\n",
            " ['Germany' 40.0 nan]\n",
            " ['France' 35.0 58000.0]\n",
            " ['Spain' nan 52000.0]\n",
            " ['France' 48.0 79000.0]\n",
            " ['Germany' 50.0 83000.0]\n",
            " ['France' 37.0 67000.0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "64yMlT6pPzWv",
        "outputId": "93bb5c24-b5e7-4ec6-bb68-46043eb60654"
      },
      "source": [
        "print(y) #printing matrix of dependent variable column"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['No']\n",
            " ['Yes']\n",
            " ['No']\n",
            " ['No']\n",
            " ['Yes']\n",
            " ['Yes']\n",
            " ['No']\n",
            " ['Yes']\n",
            " ['No']\n",
            " ['Yes']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZTjS1X7TQv4O"
      },
      "source": [
        "### Taking care of missing Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BSJmHgryQymc"
      },
      "source": [
        "# Method 1: remove rows\n",
        "\n",
        "# Method 2: Replace missing values by avg of available values\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jhyPAEX0RFon"
      },
      "source": [
        "# Method 2:\n",
        "\n",
        "from sklearn.impute import SimpleImputer #Importing useful module from sklearn\n",
        "imputer = SimpleImputer(missing_values = np.nan, strategy = 'mean') #Creating object of class SimpleImputer and using mean strategy\n",
        "imputer.fit(x[:,1:3]) #looks all the missing values in age and salary column\n",
        "x[:,1:3] = imputer.transform(x[:,1:3]) #update x with new transformed values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9zvmThJAT7Mf",
        "outputId": "831fd0fc-3a5e-4237-ea72-2326674c12f4"
      },
      "source": [
        "x"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([['France', 44.0, 72000.0],\n",
              "       ['Spain', 27.0, 48000.0],\n",
              "       ['Germany', 30.0, 54000.0],\n",
              "       ['Spain', 38.0, 61000.0],\n",
              "       ['Germany', 40.0, 63777.77777777778],\n",
              "       ['France', 35.0, 58000.0],\n",
              "       ['Spain', 38.77777777777778, 52000.0],\n",
              "       ['France', 48.0, 79000.0],\n",
              "       ['Germany', 50.0, 83000.0],\n",
              "       ['France', 37.0, 67000.0]], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eLQAaG-incln"
      },
      "source": [
        "### Encoding Categorical Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NE3D0lW9n7SY"
      },
      "source": [
        "Categorial Data means Category(Country and Purchased) column.i.e., non-numeric values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yad-0DRgVgAk"
      },
      "source": [
        "Here independent variables include country column."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0BcMkRlwSkxF"
      },
      "source": [
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "id": "i84uOKRposRV",
        "outputId": "74aafb5e-27c6-4124-f85a-1b0bbbb4103c"
      },
      "source": [
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder #creates binary vectors for each categorical vector\n",
        "ct = ColumnTransformer(transformers=[('encoder',OneHotEncoder(),[0])],remainder='passthrough') #ct object is column transformer object\n",
        "x = np.array(ct.fit_transform(x)) #convert ct into numpy array\n",
        "\n",
        "# encoder means encode column i nto matrix form -> i.e., France - [1,0,0], Spain - [0,1,0], Germany - [0,0,1]\n",
        "# OneHotEncoder encodes the categorial column and 0 is the index of the column we need to encode\n",
        "\n",
        "\"\"\"\n",
        "remainder = passthrough will include the columns which are not transformed.\n",
        "If we don't use it, it will take only first column in x. (Try it.)\n",
        "\n",
        " \n",
        "Here note that it is necessary to convert columns into numeric values in order to use it in ML\n",
        "model training. Moreover, rather than giving values like 0,1,2,3, the numpy arrays like\n",
        "[1,0,0,0],[0,1,0,0],[0,0,1,0],[0,0,0,1] are given so that we can perform operations \n",
        "of numpy library.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nremainder = passthrough will give respective values to all rows of country column.\\n            Otherwise only first 3 rows will be transformed because it has all possible\\n            values of country.\\n\\nHere note that it is necessary to convert columns into numeric values in order to use it in ML\\nmodel training. Moreover, rather than giving values like 0,1,2,3, the numpy arrays like\\n[1,0,0,0],[0,1,0,0],[0,0,1,0],[0,0,0,1] are given so that we can perform operations \\nof numpy library.\\n\\n'"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0aT7svB8rbdG",
        "outputId": "e781d0c5-e13e-41bd-da48-844de0736af4"
      },
      "source": [
        "print(x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1.0 0.0 0.0 44.0 72000.0]\n",
            " [0.0 0.0 1.0 27.0 48000.0]\n",
            " [0.0 1.0 0.0 30.0 54000.0]\n",
            " [0.0 0.0 1.0 38.0 61000.0]\n",
            " [0.0 1.0 0.0 40.0 63777.77777777778]\n",
            " [1.0 0.0 0.0 35.0 58000.0]\n",
            " [0.0 0.0 1.0 38.77777777777778 52000.0]\n",
            " [1.0 0.0 0.0 48.0 79000.0]\n",
            " [0.0 1.0 0.0 50.0 83000.0]\n",
            " [1.0 0.0 0.0 37.0 67000.0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Hd3sbx5r0RW"
      },
      "source": [
        "### Encoding the Dependent Variable"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WLbNVpSSsHOL"
      },
      "source": [
        "Dependent variable means Purchased Column. (It is called Label)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y6mGOujnr4Nf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5465eb7d-39ef-4d72-ea9b-41ee0cd92ecb"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder \n",
        "le = LabelEncoder()\n",
        "y = le.fit_transform(y) #no need to convert to numpy array as it is dependent variable\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:251: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3DrOw6Kvs3nT",
        "outputId": "32215905-ad3e-4aef-ee63-0d99366fb153"
      },
      "source": [
        "print(y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 1 0 0 1 1 0 1 0 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HMh-2CnMtF5H"
      },
      "source": [
        "### Splitting Dataset into Training Set and Testing Set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jqbDrpOxt6o4"
      },
      "source": [
        "Making two seperate sets one for training model and other for testing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QUqUYGBntLYi"
      },
      "source": [
        "# from sklearn.model_selection import train_test_split\n",
        "\n",
        "# x_train,x_test,y_train,y_test = train_test_split(x, y, test_size = 0.2, random_state=1) #random_state = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DOA8Wrwb9_fF"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size = 0.2, random_state = 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wgvn8QfPxw1G",
        "outputId": "72975fa4-ce0d-4f8a-dc24-a76c8eb30805"
      },
      "source": [
        "print(x_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.0 1.0 0.0 40.0 63777.77777777778]\n",
            " [1.0 0.0 0.0 37.0 67000.0]\n",
            " [0.0 0.0 1.0 27.0 48000.0]\n",
            " [0.0 0.0 1.0 38.77777777777778 52000.0]\n",
            " [1.0 0.0 0.0 48.0 79000.0]\n",
            " [0.0 0.0 1.0 38.0 61000.0]\n",
            " [1.0 0.0 0.0 44.0 72000.0]\n",
            " [1.0 0.0 0.0 35.0 58000.0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G5wB-dxmxzBh",
        "outputId": "0aae52b9-3180-4d31-fffc-4f61e6fb41f2"
      },
      "source": [
        "print(x_test) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.0 1.0 0.0 30.0 54000.0]\n",
            " [0.0 1.0 0.0 50.0 83000.0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_GFcXKXmx1O5",
        "outputId": "ed8cf53a-a110-458f-ee1a-cebb42ad62a7"
      },
      "source": [
        "print(y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 1 1 0 1 0 0 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-s0D5m0Kx2r3",
        "outputId": "1aff7348-9929-4ae4-d378-624d23dae102"
      },
      "source": [
        "print(y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uIecwikBtYrf"
      },
      "source": [
        "### Feature Scaling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Sn8k2FNuEnF"
      },
      "source": [
        "Scaling all features to make sure all take values in the same scale. It prevents one feature to dominate the other, which therefore will be neglected by machine learning model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g5VzzTxFtdyZ"
      },
      "source": [
        "\n",
        "\n",
        "*   **Apply Feature Scaling after Splitting Dataset into Training and Testing. It prevents information leakage on the test set which we are not supposed to have until the training is done.**\n",
        "\n",
        "*  **Applying Feature Scaling before Train-Test split means getting the mean and the standard deviation of the feature before Split. It will get the mean and std of all the values including Test Data which we are not supposed to do. Test Data must be prevented to get used by machine learning model(even in terms of feature scaling).** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "uA_0zUkJ16gC",
        "outputId": "0d8eb5bf-af57-4763-d2f8-07a3060ba0ba"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "x_train[:,3:] = sc.fit_transform(x_train[:, 3:]) #all rows, last two columns\n",
        "x_test[:,3:] = sc.fit_transform(x_test[:, 3:]) #all rows, last two columns\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "  Here note that first 3 columns represents one country. i.e., 1 0 0 means france.\n",
        "  We must not include the columns which are created by encoding. Otherwise it will\n",
        "  transform 1 0 0 into normalized form. \n",
        "\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n\\n  Here note that first 3 columns represents one country. i.e., 1 0 0 means france.\\n  We must not include the columns which are created by encoding. Otherwise it will\\n  transform 1 0 0 into normalized form. \\n\\n'"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "nbYfe_807aZV",
        "outputId": "9206d373-57f6-48f5-cee2-c860d9b18870"
      },
      "source": [
        "\"\"\"\n",
        "\n",
        "fit method will compute mean and standard deviation of feature.\n",
        "transform method will transform the values according to the scaling formula. \n",
        "\n",
        "Feature Scaling methods:\n",
        "\n",
        "1) Standardization\n",
        "\n",
        "          x - mean(x)\n",
        "Xstd. =   -----------\n",
        "            std(x)\n",
        "\n",
        "\n",
        "2) Normalization\n",
        "\n",
        "          x - min(x)\n",
        "Xnorm = ----------------\n",
        "        max(x) - min(x)\n",
        "\n",
        "\n",
        "Standardization is suitable for all cases, whereas normalization is preferred \n",
        "when normal distribution in most of the features.\n",
        "\n",
        "\"\"\"\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n\\nfit method will compute mean and standard deviation of feature.\\ntransform method will transform the values according to the scaling formula. \\n\\nFeature Scaling methods:\\n\\n1) Standardisation\\n\\n          x - mean(x)\\nXstd. =   -----------\\n            std(x)\\n\\n\\n2) Normalisation\\n\\n          x - min(x)\\nXnorm = ----------------\\n        max(x) - min(x)\\n\\n\\nStandardisation is suitable for all cases, whereas normalization is preferred \\nwhen normal distribution in most of the features.\\n\\n'"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lVtxCxXh8AWV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e23eb6d3-f72d-4823-afd4-d03e7f9eabf1"
      },
      "source": [
        "print(x_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.0 1.0 0.0 0.2630675731713538 0.1238147854838185]\n",
            " [1.0 0.0 0.0 -0.25350147960148617 0.4617563176278856]\n",
            " [0.0 0.0 1.0 -1.9753983221776195 -1.5309334063940294]\n",
            " [0.0 0.0 1.0 0.05261351463427101 -1.1114197802841526]\n",
            " [1.0 0.0 0.0 1.6405850472322605 1.7202971959575162]\n",
            " [0.0 0.0 1.0 -0.08131179534387283 -0.16751412153692966]\n",
            " [1.0 0.0 0.0 0.9518263102018072 0.9861483502652316]\n",
            " [1.0 0.0 0.0 -0.5978808481167128 -0.48214934111933727]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2h47yGn_8CG-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a02f30b-b133-4787-f212-ac1492411694"
      },
      "source": [
        "print(x_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.0 1.0 0.0 -1.0 -1.0]\n",
            " [0.0 1.0 0.0 1.0 1.0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NwA_ES_qaTxC"
      },
      "source": [
        "**There is data preprocessing template that shows this functions ready-made. Hence, if needed, we can take reference from the template.** "
      ]
    }
  ]
}